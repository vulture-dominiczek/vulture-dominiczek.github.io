(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[425],{3905:function(e,t,n){"use strict";n.d(t,{kt:function(){return d}});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),u=function(e){var t=r.useContext(l),n=t;return e&&(n="function"===typeof e?e(t):a(a({},t),e)),n},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=u(n),h=o,m=d["".concat(l,".").concat(h)]||d[h]||c[h]||i;return n?r.createElement(m,a(a({ref:t},p),{},{components:n})):r.createElement(m,a({ref:t},p))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"===typeof e||o){var i=n.length,a=new Array(i);a[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"===typeof e?e:o,a[1]=s;for(var u=2;u<i;u++)a[u]=n[u];return r.createElement.apply(null,a)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},1683:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/posts/c-language-server-p3",function(){return n(1198)}])},1198:function(e,t,n){"use strict";n.r(t),n.d(t,{default:function(){return l}});n(7294);var r=n(3905),o=n(9008);function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var a={},s=function(e){var t=e.children;return(0,r.kt)("main",{className:"md:w-3/5 text-lg mr-auto ml-auto mt-20 pb-20 article"},t)};function l(e){var t=e.components,n=i(e,["components"]);return(0,r.kt)(s,Object.assign({},a,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)(o.default,{mdxType:"Head"},(0,r.kt)("script",{defer:!0},"hljs.highlightAll();"),(0,r.kt)("title",null,"C language server: performance optimisation"),(0,r.kt)("meta",{name:"Description",content:"C language server making of: resolution of performance bottlenecks"})),(0,r.kt)("h1",null,"C language server: performance optimization"),(0,r.kt)("p",null,"Here I'm continuing C language server series. In previuos ",(0,r.kt)("a",{href:"/posts/c-language-server-p2"},"part"),"\nI wrote about crosslinking symbols and types\nbetween different source files. Each symbol tree is stored in hashmap by absolute path and symbols have ",(0,r.kt)("b",null,"jump_to")," reference to their defining type possibly in another file."),(0,r.kt)("p",null,"I intended to jump straight to vscode plugin implementation however I met couple of obstacles.\nI did some scale experiment with current code - I run indexing on kernel source code. What I found is that it would\ntake really long time to finish parsing not mentioning crosslinking. So first I will write about performance tuning\nof native applications. I reached couple of interesting conclusions about what is not performant in C++. I will\nwrite about each thing in separate section."),(0,r.kt)("h3",null,"Digression: why code navigation is lazy in VSCode"),(0,r.kt)("p",null,"What brought me to writing language server was fact that I wasn't able to quickly get all usages of\nthe type. In current c++ language support it just scans all the files, obviously it doesn't store any index. But when I have run\nmy code on kernel sources I see the reason why. Some projects are really big, so it doesn't make sense to precompute\nany index on them, because it would take ages."),(0,r.kt)("p",null," What plugins do is that they parse current source file and given the\nimports they can quickly fetch other files, parse them and reach the definition. So everyhing is on demand. The problem\nis of course finding all the usages because that would require aforementioned index."),(0,r.kt)("p",null,"Some IDE's however tend to take opposite approach and put every file in index. For example as a Java programmer\nI am used to IntelliJ and for big projects it takes at most 30 seconds to index. This makes me wonder how is it possible.\nTo beat parsing 100 files per second is almost impossible on commodity hardware, so either they employ smart heuristics,\nor they precompute the indexes (for standard lib, for ex.) and ship them with the IDE. Or maybe it is a mix of them...\nSome day maybe I will look at the source code to see. "),(0,r.kt)("p",null,"I was trying to make the most of my PC. I used ",(0,r.kt)("b",null,"valgrind")," with it's ui ",(0,r.kt)("b",null,"kcachegrind")," to debug stuff.\nThe pattern was simple: I sampled the running application on kernel sources. Then checked which method takes most\ntime percentage and fixed that. So to reach optimal performance\nI had to polish some part's of the code and they are described in secions below:"),(0,r.kt)("h3",null,"C-string to String coversions"),(0,r.kt)("p",null,"To my utmost surprise "),(0,r.kt)("pre",{className:"mt-8"},(0,r.kt)("code",{className:"language-c"},"\nstd::basic_string<CharT,Traits,Allocator>::length\n")),(0,r.kt)("p",null,"took the most of the time. Tree sitter is in C so it's API passes zero terminated strings. Originally I used  ",(0,r.kt)("b",null,"std::string")," because it has == operator overloaded.\nAnd string (I assume) stores length component as well. So when string is constructed from C-string it must iterate through all chars\nto get the length."),(0,r.kt)("p",null,"Counting around 100 symbols/definitions/references per file for thousand files it would give a lot of\nconversions. This may seem small but each identifier is several characters so it all sums up eventually. So to\ngive it a performance boost I had to give up string's == to strcmp and this eliminated this occurence."),(0,r.kt)("h3",null,"Move semantics"),(0,r.kt)("p",null,"This wasn't an issue here but thought I would mention it briefly. Some time ago in C++11 there was new construct introduced.\nThe reason was that the objects managing some external objects on the heap were previously duplicated by copy constructor and\ncopying takes time. To gain performance we can instead switch reference from right object to left object in the constructor\nand no copying takes place."),(0,r.kt)("p",null,"So this achieved by having 2 types of objects:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("b",null,"lvalue")," - it has assigned name and address"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("b",null,"rvalue")," - it is temporary object for which you can't dereference")),(0,r.kt)("p",null,"Now if you switch lvalue with rvalue in the move constructor you can move rvalues state to lvalue and rvalue object is temporary\neither way so we won't use it any more."),(0,r.kt)("p",null,"By using ",(0,r.kt)("b",null,"std::move")," we cast the objects reference to rvalue and by such we can use it in move constructor, but can't use\nit anymore in any other place."),(0,r.kt)("b",null,"Smart pointer")," ",(0,r.kt)("b",null,"std::unique_ptr"),"  already uses this semantics and can be used C++11 upwards.",(0,r.kt)("h3",null,"Pairs and tuples"),(0,r.kt)("p",null,"My first idea was to hold hashmap key as as tuple and it was a mistake. So here is my lesson of the day, ",(0,r.kt)("b",null,"structs are fast and tuples are slow"),".\nAny time you want to access tuples component you have to invoke templated method instead reach to the field. On the margin it is\nterribly inconvenient either way."),(0,r.kt)("p",null,"So I rewrote the key to struct with == operator overloaded and specialized hash template in std namespace as required. It had a huge speedup. "),(0,r.kt)("h3",null,"Unnecessary vectors"),(0,r.kt)("p",null,"So another place in found inefficiency was that while I was parsing the CST I stored temporary ",(0,r.kt)("b",null,"vector")," for every node. Maybe it is not big deal\nbut when the code is invoked hundreds of thousands of times it all sums up."),(0,r.kt)("p",null,"So what I did I somehow mimicked ",(0,r.kt)("b",null,"newtype")," pattern from Rust | Haskell. I wrapped C structure ",(0,r.kt)("b",null,"TSNode")," in a class and this\nhelped me to implement methods that delagated to ",(0,r.kt)("b",null,"ts_node_child_count")," and ",(0,r.kt)("b",null,"ts_node_child")," passing this structure but\nmaking it like a call on object."),(0,r.kt)("h3",null,"Regex"),(0,r.kt)("p",null,"First thing with regex is that it needs to be compiled and this takes time. This took 80% of remaining time in valgrind.\nFirst I tried to replace C++ regex with Google's Re2, but still performance problems persisted. On the margin,\nRe2 is definitely nicer to use. "),(0,r.kt)("p",null,' Regex is kind of swiss army knife made for everything. This complexity costs performance penalty and it was not needed for my use case anyways.\nI only needed to normalize references to the "dot separated string" so\nI extended the ',(0,r.kt)("b",null,"build_stack_graph")," for parsing CST with expressions.\nIf it was field expression it recursed prepending field with dot."),(0,r.kt)("h3",null,"Conclusion"),(0,r.kt)("p",null,"That's it. I knew that I optimized away most of stuff when Tree Sitters API's percentage in performance samples was around 80%.\nSo after doing all this I reached performance of indexing 50 files/second. It is quite nice.\nLinux kernel is medium sized project and it takes around 1,5 minute to index it. It would be nice for bigger projects\nto save index to file when indexing is done but I will pass it for now."),(0,r.kt)("p",null,'Now I\'m free to implement "frontend". I will describe it in the next (last) episode. I hope that you learned something\nuseful. Thanks for reading.'),(0,r.kt)("br",null),(0,r.kt)("br",null))}l.isMDXComponent=!0},9008:function(e,t,n){e.exports=n(5443)}},function(e){e.O(0,[774,888,179],(function(){return t=1683,e(e.s=t);var t}));var t=e.O();_N_E=t}]);